# -*- coding: utf-8 -*-
"""TugasMandiri_03

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fUu0vt5acWhToKUEgZBmSbjsYxBeJ_7i

Tugas Mandiri Minggu ke-3 | Amaya Eshia - 0110224102 - ML Siang - AI_02
"""

import statsmodels.api as sm
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

# menghubungkan colab dengan google drive
from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv('/content/drive/MyDrive/Praktikum Machine Learning_Amaya Eshia_0110224102_Ai02/Praktikum 3/Data/day.csv')
df.head()

df.describe()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

# Load dataset
df = pd.read_csv('/content/drive/MyDrive/Praktikum Machine Learning_Amaya Eshia_0110224102_Ai02/Praktikum 3/Data/day.csv', sep=',')

# Lihat 5 baris pertama
df.head()

# Info dataset
print(df.info())
print("\n")
print(df.describe())

# Cek missing values
print("\nMissing values:")
print(df.isnull().sum())

# Lihat korelasi dengan cnt
print("\nKorelasi dengan cnt:")
print(df.select_dtypes(include=np.number).corr()['cnt'].sort_values(ascending=False))

# Heatmap korelasi
plt.figure(figsize=(12, 8))
correlation_matrix = df.select_dtypes(include=np.number).corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correlation Matrix')
plt.show()

# Korelasi spesifik dengan cnt
plt.figure(figsize=(10, 6))
df.select_dtypes(include=np.number).corr()['cnt'].sort_values(ascending=False).plot(kind='bar')
plt.title('Korelasi variabel dengan cnt')
plt.ylabel('Correlation')
plt.show()

# Berdasarkan korelasi, pilih variabel yang paling berpengaruh
# Contoh: temp, atemp, hum, windspeed (sesuaikan dengan hasil analisis korelasi)

# Variabel independent (X) - pilih kolom yang relevan
X = df[['temp', 'atemp', 'hum', 'windspeed', 'season', 'yr', 'mnth',
        'holiday', 'weekday', 'workingday', 'weathersit']]

# Variabel dependent (Y)
y = df['cnt']

print("Shape X:", X.shape)
print("Shape y:", y.shape)

# Split data 80% training, 20% testing
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print("Jumlah data training:", len(X_train))
print("Jumlah data testing:", len(X_test))

# Buat model
model = LinearRegression()

# Training model
model.fit(X_train, y_train)

# Koefisien
print("Koefisien:", model.coef_)
print("Intercept:", model.intercept_)

# Prediksi
y_pred_train = model.predict(X_train)
y_pred_test = model.predict(X_test)

# Evaluasi
print("=== Evaluasi Model ===")
print(f"R² Score (train): {r2_score(y_train, y_pred_train):.4f}")
print(f"R² Score (test): {r2_score(y_test, y_pred_test):.4f}")
print(f"MAE (test): {mean_absolute_error(y_test, y_pred_test):.4f}")
print(f"MSE (test): {mean_squared_error(y_test, y_pred_test):.4f}")
print(f"RMSE (test): {np.sqrt(mean_squared_error(y_test, y_pred_test)):.4f}")

# Scatter plot actual vs predicted
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred_test, alpha=0.5, color='blue', label='Data Test')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()],
         'r--', lw=2, label='Perfect Prediction')
plt.xlabel('Actual cnt')
plt.ylabel('Predicted cnt')
plt.title('Actual vs Predicted - Bike Sharing')
plt.legend()
plt.grid(True)
plt.show()

# Residual plot
residuals = y_test - y_pred_test
plt.figure(figsize=(10, 6))
plt.scatter(y_pred_test, residuals, alpha=0.5)
plt.axhline(y=0, color='r', linestyle='--')
plt.xlabel('Predicted Values')
plt.ylabel('Residuals')
plt.title('Residual Plot')
plt.grid(True)
plt.show()

# Buat dataframe hasil
hasil = pd.DataFrame({
    'Actual': y_test.values,
    'Predicted': y_pred_test,
    'Error': y_test.values - y_pred_test
})

print(hasil.head(10))

# Statistik error
print("\n=== Statistik Error ===")
print(f"Mean Error: {hasil['Error'].mean():.4f}")
print(f"Std Error: {hasil['Error'].std():.4f}")

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import statsmodels.api as sm
from statsmodels.formula.api import ols

# 1. Load Data
df = pd.read_csv('/content/drive/MyDrive/Praktikum Machine Learning_Amaya Eshia_0110224102_Ai02/Praktikum 3/Data/day.csv', sep=',')

# 2. Pilih variabel (sesuaikan dengan kasus bike-sharing)
# Untuk dataset bike-sharing, kita bisa pakai temp, atemp, hum, windspeed, dll
# Contoh saya pakai beberapa variabel penting:

# Pastikan data sudah dibersihkan
print("Shape data:", df.shape)
print(df.info())

# 3. Cek korelasi dengan cnt terlebih dahulu
print("\nKorelasi dengan cnt:")
print(df.select_dtypes(include=np.number).corr()['cnt'].sort_values(ascending=False))

# 4. Pilih variabel independent dengan korelasi tinggi
# Misalnya: temp, atemp, hum, yr, season
X = df[['temp', 'atemp', 'hum', 'windspeed', 'yr', 'season', 'weathersit']]
y = df['cnt']

# 5. Split data
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(f"\nJumlah data training: {len(X_train)}")
print(f"Jumlah data testing: {len(X_test)}")

# 6. METODE 1: Menggunakan Statsmodels untuk hasil detail OLS
print("\n" + "="*80)
print("METODE 1: STATSMODELS OLS REGRESSION")
print("="*80)

# Tambahkan konstanta untuk statsmodels
X_train_sm = sm.add_constant(X_train)
X_test_sm = sm.add_constant(X_test)

# Fit model
model_sm = sm.OLS(y_train, X_train_sm)
results = model_sm.fit()

# Tampilkan hasil lengkap
print(results.summary())

# 7. METODE 2: Menggunakan Sklearn (lebih sederhana)
print("\n" + "="*80)
print("METODE 2: SKLEARN LINEAR REGRESSION")
print("="*80)

model_sk = LinearRegression()
model_sk.fit(X_train, y_train)

# Prediksi
y_pred_train = model_sk.predict(X_train)
y_pred_test = model_sk.predict(X_test)

# Evaluasi
r2_train = r2_score(y_train, y_pred_train)
r2_test = r2_score(y_test, y_pred_test)
mae = mean_absolute_error(y_test, y_pred_test)
mse = mean_squared_error(y_test, y_pred_test)
rmse = np.sqrt(mse)

print(f"\nR² Score (Training): {r2_train:.4f}")
print(f"R² Score (Testing): {r2_test:.4f}")
print(f"MAE: {mae:.4f}")
print(f"MSE: {mse:.4f}")
print(f"RMSE: {rmse:.4f}")

print("\nKoefisien Regresi:")
print(f"Intercept: {model_sk.intercept_:.4f}")
for i, col in enumerate(X.columns):
    print(f"  {col}: {model_sk.coef_[i]:.4f}")

# 8. VISUALISASI HASIL
fig, axes = plt.subplots(2, 2, figsize=(15, 12))

# Plot 1: Actual vs Predicted (Training)
axes[0, 0].scatter(y_train, y_pred_train, alpha=0.5, color='blue', s=20)
axes[0, 0].plot([y_train.min(), y_train.max()],
                [y_train.min(), y_train.max()],
                'r--', lw=2, label='Perfect Prediction')
axes[0, 0].set_xlabel('Actual cnt (Training)', fontsize=12)
axes[0, 0].set_ylabel('Predicted cnt', fontsize=12)
axes[0, 0].set_title(f'Training Data: Actual vs Predicted\nR² = {r2_train:.4f}',
                     fontsize=12, fontweight='bold')
axes[0, 0].legend()
axes[0, 0].grid(True, alpha=0.3)

# Plot 2: Actual vs Predicted (Testing)
axes[0, 1].scatter(y_test, y_pred_test, alpha=0.5, color='green', s=20)
axes[0, 1].plot([y_test.min(), y_test.max()],
                [y_test.min(), y_test.max()],
                'r--', lw=2, label='Perfect Prediction')
axes[0, 1].set_xlabel('Actual cnt (Testing)', fontsize=12)
axes[0, 1].set_ylabel('Predicted cnt', fontsize=12)
axes[0, 1].set_title(f'Testing Data: Actual vs Predicted\nR² = {r2_test:.4f}',
                     fontsize=12, fontweight='bold')
axes[0, 1].legend()
axes[0, 1].grid(True, alpha=0.3)

# Plot 3: Residual Plot
residuals_test = y_test - y_pred_test
axes[1, 0].scatter(y_pred_test, residuals_test, alpha=0.5, color='purple')
axes[1, 0].axhline(y=0, color='r', linestyle='--', lw=2)
axes[1, 0].set_xlabel('Predicted Values', fontsize=12)
axes[1, 0].set_ylabel('Residuals', fontsize=12)
axes[1, 0].set_title('Residual Plot (Testing Data)', fontsize=12, fontweight='bold')
axes[1, 0].grid(True, alpha=0.3)

# Plot 4: Distribution of Residuals
axes[1, 1].hist(residuals_test, bins=50, color='orange', edgecolor='black', alpha=0.7)
axes[1, 1].axvline(x=0, color='r', linestyle='--', lw=2)
axes[1, 1].set_xlabel('Residuals', fontsize=12)
axes[1, 1].set_ylabel('Frequency', fontsize=12)
axes[1, 1].set_title('Distribution of Residuals', fontsize=12, fontweight='bold')
axes[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('regression_results.png', dpi=300, bbox_inches='tight')
plt.show()

# 9. VISUALISASI KOEFISIEN
plt.figure(figsize=(10, 6))
coef_df = pd.DataFrame({
    'Feature': X.columns,
    'Coefficient': model_sk.coef_
}).sort_values('Coefficient', ascending=True)

plt.barh(coef_df['Feature'], coef_df['Coefficient'], color='steelblue')
plt.xlabel('Coefficient Value', fontsize=12)
plt.ylabel('Features', fontsize=12)
plt.title('Feature Coefficients in Linear Regression Model',
          fontsize=14, fontweight='bold')
plt.axvline(x=0, color='red', linestyle='--', linewidth=1)
plt.grid(axis='x', alpha=0.3)
plt.tight_layout()
plt.savefig('coefficients.png', dpi=300, bbox_inches='tight')
plt.show()

# 10. TABEL HASIL PREDIKSI
hasil = pd.DataFrame({
    'Actual': y_test.values,
    'Predicted': y_pred_test,
    'Error': residuals_test,
    'Error_Pct': (residuals_test / y_test.values * 100)
})

print("\n" + "="*80)
print("SAMPLE HASIL PREDIKSI (10 data pertama):")
print("="*80)
print(hasil.head(10).to_string())

print("\n" + "="*80)
print("STATISTIK ERROR:")
print("="*80)
print(f"Mean Error: {hasil['Error'].mean():.4f}")
print(f"Std Error: {hasil['Error'].std():.4f}")
print(f"Min Error: {hasil['Error'].min():.4f}")
print(f"Max Error: {hasil['Error'].max():.4f}")
print(f"Mean Absolute Error: {hasil['Error'].abs().mean():.4f}")
print(f"Mean Error Percentage: {hasil['Error_Pct'].mean():.2f}%")

# 11. INTERPRETASI MODEL
print("\n" + "="*80)
print("INTERPRETASI MODEL:")
print("="*80)
print(f"1. Model mampu menjelaskan {r2_test*100:.2f}% variasi dalam data cnt")
print(f"2. Rata-rata kesalahan prediksi (MAE): {mae:.2f} unit cnt")
print(f"3. Root Mean Squared Error (RMSE): {rmse:.2f} unit cnt")
print(f"4. Variabel dengan pengaruh terbesar:")
for i, col in enumerate(X.columns):
    print(f"   - {col}: {model_sk.coef_[i]:.4f}")